{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic_Heuristic_Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Parameters is a file with data\n",
    "import Parameters as params\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(dir_data, file_name):\n",
    "    \"\"\"THis function imports the data that it is in dir_data+file_name\"\"\"\n",
    "    with open (dir_data+file_name, \"rb\") as fp:\n",
    "        return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(file_name, file_data):\n",
    "    \"\"\"Esta funcion me permite salvar en un fichero con nombbre file_data la informaciÃ³n contenida en file_data\"\"\"\n",
    "    with open(file_name, \"wb\") as fp:\n",
    "        pickle.dump(file_data, fp)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = params.dir_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate locations\n",
    "Nc = import_data(dir_data, \"ListMECInstalled\")    # candidate coordenadas\n",
    "Nc = sorted(Nc , key=lambda k: [k[1], k[0]])\n",
    "capacity_nc = import_data(dir_data, \"Dict_C_c\") \n",
    "\n",
    "\n",
    "# access nodes\n",
    "Nr = import_data(dir_data, \"BS_pos\")\n",
    "Nr = sorted(Nr , key=lambda k: [k[1], k[0]])\n",
    "\n",
    "# Set of all nodes\n",
    "N = Nc + Nr                                     \n",
    "\n",
    "\n",
    "#VNFs data\n",
    "capacity_ct = import_data(dir_data,'Dict_C_t')             # VNF capacity\n",
    "Dict_Tproc = import_data(dir_data,'Dict_Tproc')            # VNF processing time\n",
    "T_an = params.T_an                      # Processing time of access nodes (RTT)  (us)\n",
    "T_dn = params.T_dn                      # Processing time of data network (us)\n",
    "M_t = import_data(dir_data,'M_t')       # M_t: Max number of intances for a VNF type \n",
    "T = params.Type_sfc                     # T: Types of VNFs\n",
    "alpha = params.ALPHA\n",
    "\n",
    "#Importing paths data \n",
    "Edges = import_data(dir_data,\"Edges\")                              # dict with key nodes_id (en & ran) and value latency\n",
    "Dict_Links_Capacity = import_data(dir_data,\"Dict_Links_Capacity\")  # dict with key nodes_id (en & ran) and value bandwidth                                                               # and value \n",
    "Paths = import_data(dir_data,\"Paths\")\n",
    "Paths_nm = import_data(dir_data,\"Paths_nm\")                        # dict  with key nodes_id (en & ran) and value number of paths\n",
    "Paths_links_mapping = import_data(dir_data,'Paths_links_mapping')  # W_p_uv: 1 if link uv belongs to path p\n",
    "\n",
    "\n",
    "# Session information \n",
    "S = import_data(dir_data, \"S\")                    # Number of users (i.e., PDU sessions or SFCR)\n",
    "users_sourceBS = import_data(dir_data, \"users_sourceBS\")            # source BS of each user/session\n",
    "SessionInfo_h = import_data(dir_data, 'SessionInfo_S'+str(S)) \n",
    "SessionInfo_h['SourceBS'] = [Nr.index(k)+1+len(Nc) for k in users_sourceBS.values()][:S]\n",
    "\n",
    "\n",
    "# Current placement conditions\n",
    "Paths_sfc_vnf_h = import_data(dir_data, \"Paths_sfc_vnf\")\n",
    "Paths_sfc_ran_h = import_data(dir_data, \"Paths_sfc_ran\")   \n",
    "Dict_Links_availableCap_h = import_data(dir_data,'Dict_Links_availableCap') \n",
    "vnfType_location = import_data(dir_data, \"vnfType_location\")        # dict:c key & list of assigned tic\n",
    "Xtic_h = import_data(dir_data, \"Xtic\")  \n",
    "Xtic_h_capacity = import_data(dir_data, \"Xtic_capacity\")  # xtix available capacity\n",
    "Xtic_h_sessions = import_data(dir_data, \"Xtic_sessions\")  # dict: tic key & list of assigned sessions with index >= 1\n",
    "Zsfc_h = import_data(dir_data, \"Zsfc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_extrasfc_upf = params.FLAG_EXTRASFC_UPF  #allow unmapping also those sessions assigned to UPFS with low \n",
    "                                              #capacity in case of partial heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_instances_id = {}\n",
    "initial_instances_loc = {}\n",
    "\n",
    "for t,i,c  in Xtic_h:\n",
    "    initial_instances_id.setdefault(t, []).append(i)\n",
    "    initial_instances_loc[(t,i)] = c\n",
    "    \n",
    "initial_VNFid_loc = {}  #For each c, it has a dict with key type and values ids.  \n",
    "\n",
    "for c, v in vnfType_location.items():\n",
    "    initial_VNFid_loc.setdefault(c, {})\n",
    "    for t,i,c in v:\n",
    "        initial_VNFid_loc[c].setdefault(t, []).append(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost components normalization and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.167, 0.167, 0.167, 0.167, 0.166, 0.166]\n",
      "NormalizationValues [13, 12, 5, 7, 3600, 25]\n"
     ]
    }
   ],
   "source": [
    "# weight factors\n",
    "w_a = params.WEIGHT_D_EN            # NODE ACTIVATION\n",
    "w_r = params.WEIGHT_D_RUN           # VNF operation\n",
    "w_d = params.WEIGHT_D_DEP           # VNF deployment\n",
    "w_m = params.WEIGHT_D_MIG           # VNF migration\n",
    "w_l = params.WEIGHT_D_ROU           # traffic routing\n",
    "w_s = params.WEIGHT_D_REA           # session reassignment\n",
    "\n",
    "WeightFactors = [w_a, w_r, w_d, w_m, w_l, w_s]\n",
    "\n",
    "# Normalization parameters\n",
    "Branches = sum(SessionInfo_h['Branches']) \n",
    "max_latency = 100*Branches          # 100 is the average Lprop budget in one way\n",
    "max_upf = sum(M_t.values())         # Max number of VNFs is conditioned by M_t, which only includes upfs and not ran\n",
    "max_server = len(capacity_nc)\n",
    "max_newupf = max_upf-len(Xtic_h_capacity)       # MAx number of new upf that can be deployed\n",
    "if max_newupf == 0:\n",
    "    max_newupf = 1\n",
    "max_migrations = len(Xtic_h_capacity)           # MAx number of migration depends of current deployed VNFs\n",
    "max_relocations = S\n",
    "\n",
    "NormalizationValues = [max_server, max_upf, max_newupf, max_migrations, max_latency, max_relocations]\n",
    "print('NormalizationValues', NormalizationValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_initialSolution():\n",
    "    \"\"\" This function generates the initial solution which will be used during the placement reconfiguration\"\"\"\n",
    "    \n",
    "    #Initialing solution variables\n",
    "    realcapacity_servers = copy.deepcopy(capacity_nc)\n",
    "    open_servers = []\n",
    "    vnf_instances = {}    # key=type of VNF and the value=list of instances id\n",
    "    vnf_cap = {}\n",
    "    vnfinstance_server ={} # dict of dict, main dict key=node id, value = dict key=vnf_type & value=instance id\n",
    "    vnf_sfc = {}           # dict of dict, main dict key=type, valueis a dict key=instance_id & value=sfc id\n",
    "\n",
    "    for tic in Xtic_h_capacity.keys():\n",
    "        t,i,c = tic\n",
    "        if c not in open_servers:\n",
    "            open_servers.append(c)\n",
    "\n",
    "        vnf_instances.setdefault(t, [])\n",
    "        vnf_instances[t].append(i)\n",
    "\n",
    "        vnf_cap.setdefault(t, {})\n",
    "        vnf_cap[t][i] = round(Xtic_h_capacity[tic],2)  # Xtic_h_capacity available\n",
    "\n",
    "        vnfinstance_server.setdefault(c, {})\n",
    "        vnfinstance_server[c].setdefault(t, [])\n",
    "        vnfinstance_server[c][t].append(i)\n",
    "\n",
    "        vnf_sfc.setdefault(t, {})\n",
    "        vnf_sfc[t][i] = Xtic_h_sessions[tic]\n",
    "\n",
    "        realcapacity_servers[c] = round(realcapacity_servers[c] - capacity_ct[t], 2)\n",
    "\n",
    "\n",
    "    sfc_mapping = {}\n",
    "    for s,f,c  in Zsfc_h:\n",
    "        t = SessionInfo_h['Type'][s-1][f-1]\n",
    "\n",
    "        for tic, users in Xtic_h_sessions.items():\n",
    "            t1,i1,c1 = tic      \n",
    "            if ((t == t1 ) and (c == c1)) and s in users:\n",
    "                sfc_mapping.setdefault(s, {}).setdefault('VNFs', {})\n",
    "                sfc_mapping[s]['VNFs'][f] = tic\n",
    "\n",
    "    for s in range(1, S+1):\n",
    "        sfc_mapping[s]['Paths'] = [(Paths_sfc_ran_h[s])]\n",
    "        if s in Paths_sfc_vnf_h.keys():\n",
    "            sfc_mapping[s]['Paths'] += list(Paths_sfc_vnf_h[s].values())\n",
    "\n",
    "    solution = {}\n",
    "    solution['LinksCap'] = copy.deepcopy(Dict_Links_availableCap_h)       \n",
    "    solution['ServersCap'] = realcapacity_servers\n",
    "    solution['OpenServers'] = open_servers\n",
    "    solution['VNFInstances'] = vnf_instances\n",
    "    solution['VNFCapacity'] = vnf_cap\n",
    "    solution['NodeVNFInstances'] = vnfinstance_server\n",
    "    solution['VNFSFCAssigned'] = vnf_sfc\n",
    "    solution['SFCMapping'] = sfc_mapping\n",
    "\n",
    "#     # validating  sfc_mapping: commented to reduce Texec\n",
    "#     for s in range(1, S+1):\n",
    "#         if len(sfc_mapping[s]['VNFs']) != len(SessionInfo_h['VNFs'][s-1]):\n",
    "#             print('ERROR: review SFC mapping')\n",
    "#             raise\n",
    "    \n",
    "    return solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining PDU sessions  parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gathering_infoSFC(SessionInfo_h):\n",
    "    \"\"\" This function checks the current values of latency for each sfc in order to determine the sessions\n",
    "    that will be reassigned\"\"\"\n",
    "    \n",
    "    BS_popularity = dict(Counter(list(SessionInfo_h['SourceBS'])))\n",
    "    \n",
    "    # Gathering Info about the current sfc configuration\n",
    "    Lv_list = []           # 1 if a session has poor QoS (latency violation); 0 otherwise\n",
    "    Latency_budget_list = []\n",
    "    Lv_users_list = []\n",
    "    BS_pop_list = []\n",
    "    \n",
    "    # verifying latency in the user plane\n",
    "    for user in range(1,S+1):\n",
    "        lat = 0\n",
    "        ind_lv = 0\n",
    "        for b in range(SessionInfo_h['Branches'][user-1]):\n",
    "            t_proc = 2*sum(p*Dict_Tproc[u] for p,u in zip(SessionInfo_h['Presence'][user-1][b], \n",
    "                                                         SessionInfo_h['Type'][user-1])) + T_dn + T_an\n",
    "            t_prop = 2*(sum(SessionInfo_h['Order'][user-1][b][f-1][g-1]*Paths[Paths_sfc_vnf_h[user][f,g]] \n",
    "                            for f,g in Paths_sfc_vnf_h.get(user, {}).keys()) + Paths[Paths_sfc_ran_h[user]])\n",
    "            latency = round(t_proc + t_prop,2)\n",
    "            if latency > lat:\n",
    "                lat = latency\n",
    "        \n",
    "        Latency_budget_list.append(SessionInfo_h['Latency'][user-1] - lat)\n",
    "\n",
    "        if lat > SessionInfo_h['Latency'][user-1]:\n",
    "            Lv_users_list.append(user)\n",
    "            ind_lv = 1\n",
    "            \n",
    "        Lv_list.append(ind_lv)\n",
    "        BS_pop_list.append(float(str(BS_popularity[SessionInfo_h['SourceBS'][user-1]]) + '.'+ \n",
    "                                 str(SessionInfo_h['SourceBS'][user-1])))\n",
    "        \n",
    "\n",
    "    SessionInfo_h['Lbudg'] = Latency_budget_list\n",
    "    SessionInfo_h['Lv'] = Lv_list\n",
    "    SessionInfo_h['BS_pop'] = BS_pop_list\n",
    "\n",
    "    return SessionInfo_h, Lv_users_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_candidates(source_vnf, Lprop_vnf, Available_c):\n",
    "    \"\"\"This fucntion determines the candidates for the placement of a given vnf.\n",
    "    Inputs:\n",
    "    - source_vnf: The id of the source node (the previous vnf in the branch of the current vnf)\n",
    "    - Lprop_vnf: the latency budget for the propagation delay\n",
    "    - Available_c: those candidates that have capacity to instatiate a vnf or to serve a request\n",
    "    Output:\n",
    "    - List_c: A list with the position of possible candidates\n",
    "    \"\"\"      \n",
    "    List_c = []\n",
    "    \n",
    "    for kp, vp in Paths.items():\n",
    "        if kp[0] == source_vnf and vp <= min(Lprop_vnf):\n",
    "            if (kp[1] not in List_c ) and (kp[1] in Available_c):\n",
    "                List_c.append(kp[1]) \n",
    "                \n",
    "    return List_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_classifier(session_info, available_c):\n",
    "    \"\"\"This function classified the sessions as critic or not depending on their number of available candidates\n",
    "    Input:\n",
    "    - session_info: DF with info about sessions\n",
    "    - available_c: List of available candidates for the VNf placement\n",
    "    \"\"\"\n",
    "    \n",
    "    List_critic_s = []  # 1 if the session is in a critical state (few available candidates), 0 otherwise\n",
    "    List_Numcand_s = []\n",
    "    List_candidates_s = []\n",
    "    \n",
    "    for index, row in session_info.iterrows():\n",
    "        aux_list = determine_candidates(row['SourceBS'], row['L_prop'], available_c)\n",
    "\n",
    "        List_Numcand_s.append(len(aux_list))\n",
    "        List_candidates_s.append(aux_list)\n",
    "        if len(row['Type'])==1:\n",
    "            if len(aux_list)<=1:\n",
    "                List_critic_s.append(1)\n",
    "            else:\n",
    "                List_critic_s.append(0)\n",
    "        else:\n",
    "            if len(aux_list)<=2:\n",
    "                List_critic_s.append(1)\n",
    "            else:\n",
    "                List_critic_s.append(0)\n",
    "\n",
    "    session_info['Critic'] = List_critic_s \n",
    "    session_info['NumCand'] = List_Numcand_s \n",
    "    session_info['Candidates'] = List_candidates_s \n",
    "    \n",
    "    return session_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfc_releaseResources( UnmapSessionInfo_h, solution):\n",
    "    \"\"\" This function is in charge of releasing resources assigned to the SFC\n",
    "    \"\"\"\n",
    "    \n",
    "    list_sfc = []\n",
    "    \n",
    "    for ind, row in UnmapSessionInfo_h.iterrows():\n",
    "        # 1- Unmap sfc to release its assigned resources (release upfs and links capacity)\n",
    "        for t,i,c in solution['SFCMapping'][row['SessionId']]['VNFs'].values():\n",
    "            solution['VNFCapacity'][t][i] = round(solution['VNFCapacity'][t][i]  + row['Demand'],2)\n",
    "\n",
    "            if round(solution['VNFCapacity'][t][i],2) == capacity_ct[t]:\n",
    "                # update node_vnf_instance and vnf_instances\n",
    "                if len(solution['NodeVNFInstances'][c][t]) == 1:\n",
    "                    del solution['NodeVNFInstances'][c][t]\n",
    "                    if sum([len(v) for v in solution['NodeVNFInstances'][c].values()]) == 0:\n",
    "                        del  solution['NodeVNFInstances'][c]\n",
    "                else:\n",
    "                    solution['NodeVNFInstances'][c][t].remove(i)\n",
    "                    \n",
    "                #step: deleting instance from 'VNFInstances'\n",
    "                if len(solution['VNFInstances'][t]) == 1:\n",
    "                    del solution['VNFInstances'][t]\n",
    "                else: \n",
    "                    solution['VNFInstances'][t].remove(i)\n",
    "\n",
    "                if i in solution['VNFInstances_tmp'].get(t, []):\n",
    "                    solution['VNFInstances_tmp'][t].remove(i)\n",
    "                    if len(solution['VNFInstances_tmp'][t]) == 0:\n",
    "                        del solution['VNFInstances_tmp'][t]\n",
    "\n",
    "                # update server capacity:\n",
    "                solution['ServersCap'][c] = round(solution['ServersCap'][c] + capacity_ct[t], 2)\n",
    "                if solution['ServersCap'][c] == capacity_nc[c]:\n",
    "                    solution['OpenServers'].remove(c)  \n",
    "#                     print('empty server:', c)\n",
    "\n",
    "        for path in solution['SFCMapping'][row['SessionId']]['Paths']:\n",
    "            for link, map_ind in Paths_links_mapping[path].items():\n",
    "                if map_ind == 1:  \n",
    "                    # update link available capacity\n",
    "                    solution['LinksCap'][link] += row['Bw']\n",
    "\n",
    "        del solution['SFCMapping'][row['SessionId']]\n",
    "        list_sfc.append(row['SessionId'])\n",
    "           \n",
    "    for t, v in solution['VNFSFCAssigned'].items():\n",
    "        for i,users in v.items():\n",
    "            solution['VNFSFCAssigned'][t][i] = list(set(users) - set(list_sfc))\n",
    "\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unmapping_sessions(solution_y, UnmapSessionInfo_h, MappedSessionInfo_h, flag_extrasfc_upf):\n",
    "    \"\"\"This function unmaps the resources used for sessions in the current placement consideration.\n",
    "    If all the sessions are decided to be unmapped, then this procedure can be omitted.\n",
    "    It will return the set of unmapped sessionInfo updated and the solution with released resources.\n",
    "    This function is different from the one used to reassign sessions. Specifically, it is called only at \n",
    "    the begining to prepare the initial solution.\"\"\"\n",
    "    \n",
    "    solution_ = copy.deepcopy(solution_y)\n",
    "    # releasing the resources of sessions selected due to latency violations\n",
    "    solution_ = sfc_releaseResources(UnmapSessionInfo_h, solution_)\n",
    "     \n",
    "    if flag_extrasfc_upf:\n",
    "        # verifying capacity of the VNF\n",
    "        unmapedsfc = pd.DataFrame()\n",
    "        for t, v in solution_['VNFCapacity'].items():\n",
    "            for i, cap in v.items():\n",
    "                if (capacity_ct[t] - cap )/ capacity_ct[t] < params.UPF_CAP_MIN:\n",
    "                    for s in solution_['VNFSFCAssigned'][t][i]:\n",
    "                        unmapedsfc = unmapedsfc.append(MappedSessionInfo_h[MappedSessionInfo_h['SessionId']==s])\n",
    "                        MappedSessionInfo_h.drop(MappedSessionInfo_h.index[(MappedSessionInfo_h['SessionId'] == s)],\n",
    "                                               axis = 0, inplace=True)\n",
    "\n",
    "        solution_ = sfc_releaseResources(unmapedsfc, solution_)\n",
    "\n",
    "        UnmapSessionInfo_h = UnmapSessionInfo_h.append(unmapedsfc)        \n",
    "\n",
    "    return solution_, UnmapSessionInfo_h, MappedSessionInfo_h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Procedure: components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_candidate(solution_x , c, source_vnf, vnf_id, vnf_type, row, vnf_relocat_):\n",
    "    \"\"\"This function verifies that none constraint is violated if a vnf is placed at c location. \n",
    "    It also verifies the existence of a path with available capacity. In case of more than one path it returns \n",
    "    the shortest one.\n",
    "    Inputs:\n",
    "    -c: candiate node(id)\n",
    "    Outputs:\n",
    "    -List_const: list with number of constraints violated. If no constraint is exceeded, it is empty\n",
    "    -Selectd_path: selected path for the routing. default value=none\n",
    "    -VariableValues: Binary Tuple (act-ser, run-vnf, new-vnf, mig, rout, reloc). Default values  [0,0,0,0,0,0] \n",
    "    \"\"\"\n",
    "    List_const = []\n",
    "    Selected_path = None\n",
    "    VariableValues =  [0,0,0,0,0,0]   # act-ser, run-vnf, new-vnf, mig, rout, reloc\n",
    "    \n",
    "    # verifying the existence of a vnf instance of same type in the candidate\n",
    "    Instances_c = solution_x['NodeVNFInstances'].get(c, {}).get(vnf_type, None)\n",
    "    VNFCapFailure = False     \n",
    "    if Instances_c != None:  #There is at least one VNf instance of the same type. Thereby, verify instances capacity\n",
    "        VNFCapFailure = True\n",
    "        for inst in Instances_c:\n",
    "            if solution_x['VNFCapacity'][vnf_type][inst] - row['Demand'] >= (1-alpha)*capacity_ct[vnf_type]:\n",
    "                VNFCapFailure = False\n",
    "                break\n",
    "                \n",
    "    if Instances_c == None or VNFCapFailure: #There is not instances or they do not have capacity\n",
    "        if solution_x['ServersCap'][c] < capacity_ct[vnf_type]:  #the candidate does not have more capacity\n",
    "            List_const.append('C1')\n",
    "            return List_const, Selected_path, VariableValues\n",
    "            if VNFCapFailure:\n",
    "                List_const.append('C2')\n",
    "                return List_const, Selected_path, VariableValues\n",
    "        else:\n",
    "            # We should create a new instance of vnf_type, but before we need to verify the max num instances\n",
    "            if (len(solution_x['VNFInstances'].get(vnf_type,[]))+1) > M_t[vnf_type]:\n",
    "                List_const.append('C4')\n",
    "                return List_const, Selected_path, VariableValues\n",
    "    \n",
    "    # verifying UPF constraints\n",
    "    if vnf_type==1:  # It's a PSA UPF\n",
    "        for v in solution_x['SFCMapping'].get(row['SessionId'], {}).get('VNFs', {}).values():\n",
    "            # Anti-affinity constraint:\n",
    "            if v[0]==vnf_type and v[2]==c:   # v--> (type, instance, c)\n",
    "                List_const.append('C16')\n",
    "                return List_const, Selected_path, VariableValues\n",
    "            # PSA_IUPF constraint:\n",
    "            elif v[0]==2 and v[2]==c:   # v--> (type, instance, c)\n",
    "                List_const.append('C17')\n",
    "                return List_const, Selected_path, VariableValues\n",
    "                \n",
    "    \n",
    "    # finding the shortest path with available capacity\n",
    "    pathid, pathdelay = [], []\n",
    "    \n",
    "    for k,v in Paths.items():\n",
    "        if k[0]==source_vnf and k[1]==c:\n",
    "            pathid.append(k)\n",
    "            pathdelay.append(v)\n",
    "            \n",
    "    SortedPaths = [x for _,x in sorted(zip(pathdelay, pathid))]   # sorting the paths by their prop delay        \n",
    "    \n",
    "    #checking path capacity\n",
    "    for path in SortedPaths:\n",
    "        LinkCapFailure = False\n",
    "        for link,v in Paths_links_mapping[path].items():\n",
    "            if v==1 and solution_x['LinksCap'][link] < row['Bw']:\n",
    "                LinkCapFailure = True\n",
    "                break\n",
    "        if not LinkCapFailure:\n",
    "            Selected_path = path\n",
    "            break\n",
    "            \n",
    "    if Selected_path==None: \n",
    "        List_const.append('C3')\n",
    "        return List_const, Selected_path, VariableValues\n",
    "    \n",
    "    \n",
    "    # If we are at this step, it is because len(list_const)=0: No constraint violation\n",
    "\n",
    "    # Determing the VariableValues = [0,0,0,0,0,0]   # act-ser, run-vnf, new-vnf, mig, rout, reloc\n",
    "    if solution_x['NodeVNFInstances'].get(c, None) == None:\n",
    "        VariableValues[0], VariableValues[1] = 1, 1\n",
    "        # Checking previous placement to reuse vnfs if any available. This avoid new deployment and migration\n",
    "        instance = None\n",
    "        if initial_VNFid_loc.get(c, {}).get(vnf_type, None) != None: \n",
    "            for i in initial_VNFid_loc[c][vnf_type]:\n",
    "                if i not in solution_x['VNFInstances'].get(vnf_type,[]):\n",
    "                    instance = i\n",
    "                    break\n",
    "\n",
    "        # otherwise, 'determine' f it is a migration or new deploy\n",
    "        if instance == None:\n",
    "            if len(solution_x['VNFInstances'].get(vnf_type,[])) >= len(initial_instances_id.get(vnf_type,[])):\n",
    "                VariableValues[2] = 1\n",
    "            else:\n",
    "                # Verifying if there is available instances from previous placement,to use same id and\n",
    "                # avoid migration\n",
    "                VariableValues[3] = 1   # start assuming migraton\n",
    "                for ind in initial_VNFid_loc.get(c, {}).get(vnf_type, []):\n",
    "                    if ind not in solution_x['VNFInstances'].get(vnf_type, []):\n",
    "                        VariableValues[3] = 0  # no need of migration, we can use instance with same type & id\n",
    "                        break                    \n",
    "\n",
    "    elif VNFCapFailure or Instances_c == None:\n",
    "        VariableValues[1] = 1\n",
    "        # Checking previous placement to reuse vnfs if any available. This avoid new deployment and migration\n",
    "        instance = None\n",
    "        if initial_VNFid_loc.get(c, {}).get(vnf_type, None) != None: \n",
    "            for i in initial_VNFid_loc[c][vnf_type]:\n",
    "                if i not in solution_x['VNFInstances'].get(vnf_type,[]):\n",
    "                    instance = i\n",
    "                    break\n",
    "\n",
    "        # otherwise, 'determine' f it is a migration or new deploy\n",
    "        if instance == None:\n",
    "            if len(solution_x['VNFInstances'].get(vnf_type,[])) >= len(initial_instances_id.get(vnf_type,[])):\n",
    "                VariableValues[2] = 1\n",
    "            else:\n",
    "                # Verifying if there is available instances from previous placement,to use same id and\n",
    "                # avoid mig\n",
    "                VariableValues[3] = 1   # start assuming migraton\n",
    "                for ind in initial_VNFid_loc.get(c, {}).get(vnf_type, []):\n",
    "                    if ind not in solution_x['VNFInstances'].get(vnf_type, []):\n",
    "                        VariableValues[3] = 0  # no need of migration, we can use instance with same type & id\n",
    "                        break \n",
    "\n",
    "    VariableValues[4] = Paths[Selected_path] \n",
    "\n",
    "    for sfc in Zsfc_h:\n",
    "        if sfc[0] == row['SessionId'] and sfc[1] == vnf_id and c != sfc[2]:\n",
    "            VariableValues[5] = 1\n",
    "            break\n",
    "    \n",
    "    # The following steps were omitted to save time\n",
    "#     if VariableValues[2] == 1 and VariableValues[3] == 1:\n",
    "#         print('ERROR, there is either a new deployment or migration, but no both at the same time')\n",
    "#         raise\n",
    "        \n",
    "    return List_const, Selected_path, VariableValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulating_vnfdeployment(solution_2, c, vnf_id, vnf_type, Selected_path, VariableValues, row):\n",
    "    \"\"\"This function will simulate the deployment of vnf in c to analize the deployment posibilities for \n",
    "    the next vnf if the current location is selected.\n",
    "    1-To simulate the deployment we will create a copy of the sets and add the mapping of vnf to links and nodes\n",
    "    2-Find next VNF in the branch \n",
    "    3-Take c as source for vnf+1 and determine the candidates\n",
    "    3-Evaluate each candidate\n",
    "    4-Select the best candidate\n",
    "    \"\"\"  \n",
    "    #Updating the Sets\n",
    "    if VariableValues[0]==1: # Opening of a new server   \n",
    "        solution_2['OpenServers'].append(c)\n",
    "        \n",
    "    if VariableValues[1]==1: # create a new instance of vnf_type  (new deploymnet or migrtion)\n",
    "        solution_2['ServersCap'][c] -= capacity_ct[vnf_type]\n",
    "        \n",
    "        # determine index of instance (new or mig)\n",
    "        if VariableValues[2] == 1 or VariableValues[3] == 1:   # new deployment or migration\n",
    "            for ind in range(len(solution_2['VNFInstances_tmp'].get(vnf_type, []))+1):\n",
    "                if  'tmp' + str(ind+1) not in solution_2['VNFInstances_tmp'].get(vnf_type, []):\n",
    "                    instance = 'tmp' + str(ind+1)\n",
    "                    break\n",
    "#             print('temporal id', instance)\n",
    "#             print(solution_2['VNFInstances_tmp'].get(vnf_type, []))\n",
    "            solution_2['VNFInstances_tmp'].setdefault(vnf_type,[]).append(instance) \n",
    "            \n",
    "        else: \n",
    "            for ind in initial_VNFid_loc.get(c, {}).get(vnf_type, []):\n",
    "                if ind not in solution_2['VNFInstances'].get(vnf_type, []):\n",
    "                    instance = ind\n",
    "                    break \n",
    "           \n",
    "        solution_2['VNFInstances'].setdefault(vnf_type,[]).append(instance)\n",
    "        solution_2['VNFCapacity'].setdefault(vnf_type,{})[instance] = capacity_ct[vnf_type]\n",
    "        solution_2['NodeVNFInstances'].setdefault(c, {}).setdefault(vnf_type,[]).append(instance)\n",
    "    \n",
    "    else:  # find instance with capacity\n",
    "        for instance in solution_2['NodeVNFInstances'][c][vnf_type]:\n",
    "            if solution_2['VNFCapacity'][vnf_type][instance] - row['Demand'] >= (1-alpha)*capacity_ct[vnf_type]:\n",
    "                break\n",
    "    \n",
    "    # update capacity\n",
    "    solution_2['VNFCapacity'][vnf_type][instance] = round(solution_2['VNFCapacity'][vnf_type][instance]\n",
    "                                                           - row['Demand'],2)  \n",
    "    solution_2['SFCMapping'].setdefault(int(row['SessionId']), {}).setdefault('VNFs', {})[vnf_id] = (vnf_type, \n",
    "                                                                                                instance, c)\n",
    "    solution_2['SFCMapping'].setdefault(int(row['SessionId']), {}).setdefault('Paths', []).append(Selected_path)\n",
    "    solution_2['VNFSFCAssigned'].setdefault(vnf_type,{}).setdefault(instance,[]).append(int(row['SessionId']))\n",
    "\n",
    "    for link,v in Paths_links_mapping[Selected_path].items():\n",
    "        if v==1: #update link capacity\n",
    "            solution_2['LinksCap'][link]-= row['Bw']\n",
    "    \n",
    "    return solution_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_candidates(solution_x, candidates_set, source, v_id, v_type, row, vnf_relocat_):\n",
    "    \"\"\"Determines which candidates in the set are feasible and which one not for the deployment of \n",
    "    the selected vnf\n",
    "    (act-ser, run-vnf, new-vnf, mig, rout, reloc)\n",
    "    \"\"\"\n",
    "\n",
    "    feasible_cadidates = {}  \n",
    "\n",
    "    #Verify candidate\n",
    "    for c in candidates_set:\n",
    "        list_const, selected_path, variablevalues = verify_candidate(solution_x, c, source,  v_id,  v_type, row,\n",
    "                                                                     vnf_relocat_)  \n",
    "        \n",
    "        if len(list_const) == 0:   #Feasible candidate, no constraint was violated\n",
    "            cost_c = sum([(a*b)/c for a,b,c in zip(WeightFactors, variablevalues, NormalizationValues)]) \n",
    "\n",
    "            feasible_cadidates[c] = [selected_path, variablevalues, cost_c]\n",
    "\n",
    "    return feasible_cadidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_procedure(solution_copy, row, available_c, AVAILABLE_NC):\n",
    "    \"\"\" This function is in charge of mapping the vnfs in the sfcr, it will return a flag indicating the \n",
    "    state (failure or success) of the mapping procedure and a dict containing the data  associated  to the\n",
    "    output status\"\"\"\n",
    "        \n",
    "    flag_mapping_error = False      # pdt\n",
    "    VNFLoc = {}                     # dict vnf_id as key and c, lprop as value\n",
    "    vnf_relocat = {}                # dict vnf_id as key and binary indicator as value(0 no relocated)\n",
    "\n",
    "    for f_id, f_type  in zip(row['VNFs'], row['Type']):            # f_id , f_typev= vnf_id, vnf_type\n",
    "        if f_id not in VNFLoc.keys():  # If the VNF has not been mapped yet, analyze its placement solut.\n",
    "            best_cost = 1000           # set to a high value\n",
    "            destination_vnf_f = []\n",
    "            \n",
    "            for branch, Lprop in zip(row['Presence'], row['L_prop']):\n",
    "                # Steps 9-11: Select the candidates that are common to all the source according to Lprop.\n",
    "                # In our case, the source is the same for all vnf. Thus, we just need to update the candidates.\n",
    "                if f_id == 1:\n",
    "                    source_vnf_f = row['SourceBS'] # The BS is the initial source for all the branches\n",
    "                    Lprop_vnf_f = [Lprop]          # This is also updated with the placement of each VNf in a branch\n",
    "                    candidates_f = row['Candidates'] #For the first vnf they satisfy latency req\n",
    "                else:\n",
    "                    source_vnf_f = VNFLoc[1][0]    # In the case under study, it's the same source (first f)\n",
    "                    Lprop_vnf_f = VNFLoc[1][1]     # In the case under study,it's the same source (first f)\n",
    "                    candidates_f = determine_candidates(source_vnf_f, Lprop_vnf_f, available_c)\n",
    "\n",
    "                # determining if f is the last: In our specific case, is easier to see the type of the vnf. \n",
    "                # If it's the last vnf, we do not need to determine the destination_vnfs. PSA  (f_type =1) is the last vnf\n",
    "                #  in the chain\n",
    "                if f_type != 1:                             \n",
    "                    for next_f_index in range(f_id,len(row['VNFs'])):  # f_ids tarts in 1, thus if we use it to \n",
    "                                                                       # iterate,we will be looking at the next vnfs.\n",
    "                        if branch[next_f_index] == 1:     \n",
    "                            destination_vnf_f.append(row['VNFs'][next_f_index])\n",
    "                            break  \n",
    "              \n",
    "            # steps 12-14: Evaluate candidates\n",
    "            feasible_cadidates = evaluate_candidates(solution_copy,candidates_f, source_vnf_f, f_id,\n",
    "                                                     f_type, row, vnf_relocat) \n",
    "\n",
    "            # steps 17: sort feasible candidates by their cost in ascending order\n",
    "            sorted_candidates_f = sorted(feasible_cadidates.keys(), key=lambda k: feasible_cadidates[k][2])\n",
    "            \n",
    "            for c in sorted_candidates_f:\n",
    "                selected_path, variablevalues, cost = feasible_cadidates[c]\n",
    "                if cost < best_cost:\n",
    "                    # step 20 & 27: simulating deployment of vnf f\n",
    "                    VNFLoc_aux = copy.deepcopy(VNFLoc)  \n",
    "                    vnf_relocat_aux = copy.deepcopy(vnf_relocat)\n",
    "                    solution_copy2 = copy.deepcopy(solution_copy)\n",
    "                    solution_copy2 = simulating_vnfdeployment(solution_copy2, c, f_id, f_type,\n",
    "                                                              selected_path, variablevalues, row)\n",
    "                    #steps 15-: Looking-ahead\n",
    "                    if f_type !=1:                                \n",
    "                        Lprop_next_f = [Lprop_vnf_f[0] - Paths[selected_path]] \n",
    "                        candidates_next_f = determine_candidates(c, Lprop_next_f, available_c)\n",
    "                        VNFLoc_aux[f_id] = (c, Lprop_next_f) \n",
    "                        vnf_relocat_aux[f_id] = variablevalues[-1]\n",
    "                        \n",
    "                        for next_f_id in destination_vnf_f:\n",
    "                            # steps 24-25: Evaluate candidates\n",
    "                            feasible_cadidates_next_f = evaluate_candidates(solution_copy2, \n",
    "                                                                            candidates_next_f, c, \n",
    "                                                                            next_f_id, \n",
    "                                                                            row['Type'][next_f_id-1], row, \n",
    "                                                                            vnf_relocat_aux)\n",
    "                            \n",
    "                            if len(feasible_cadidates_next_f) != 0:\n",
    "                                # steps 26: selecting the best candidates for the next vnf                            \n",
    "                                best_c_next_f = sorted(feasible_cadidates_next_f.keys(), key=lambda k: \n",
    "                                                             feasible_cadidates_next_f[k][2])[0]\n",
    "                                \n",
    "                                # Step 27: simulating deployment of next vnf\n",
    "                                solution_copy2 = simulating_vnfdeployment(solution_copy2, best_c_next_f, \n",
    "                                                                          next_f_id, row['Type'][next_f_id-1],\n",
    "                                                                          feasible_cadidates_next_f[best_c_next_f][0], \n",
    "                                                                          feasible_cadidates_next_f[best_c_next_f][1],\n",
    "                                                                          row)\n",
    "                                # Step 28: Update candidate Cost\n",
    "                                cost += feasible_cadidates_next_f[best_c_next_f][2]\n",
    "                                VNFLoc_aux[next_f_id] = (best_c_next_f, Lprop_next_f[0]-\n",
    "                                                         Paths[feasible_cadidates_next_f[best_c_next_f][0]]) \n",
    "                                vnf_relocat_aux[next_f_id] = feasible_cadidates_next_f[best_c_next_f][1][-1]\n",
    "                                \n",
    "                            else: \n",
    "                                cost += 1000    \n",
    "                                break\n",
    "\n",
    "                        if cost < best_cost:\n",
    "                            best_cost = cost\n",
    "                            best_solution = copy.deepcopy(solution_copy2)\n",
    "                            VNFLoc_best = copy.deepcopy(VNFLoc_aux) \n",
    "                            vnf_relocat_best = copy.deepcopy(vnf_relocat_aux)\n",
    "                    else:\n",
    "                        best_cost = feasible_cadidates[c][2] \n",
    "                        best_solution = copy.deepcopy(solution_copy2)\n",
    "                        VNFLoc_best = copy.deepcopy(VNFLoc_aux) \n",
    "                        VNFLoc_best[f_id] = (c, [Lprop_vnf_f[0] - Paths[feasible_cadidates[c][0]]])  #pdt\n",
    "                        vnf_relocat_best = copy.deepcopy(vnf_relocat_aux)                        \n",
    "                        vnf_relocat_best[f_id] = variablevalues[-1]\n",
    "                        break  \n",
    "                                     \n",
    "            # steps 33-34:        \n",
    "            if best_cost < 1000:\n",
    "                solution_copy = copy.deepcopy(best_solution)\n",
    "                VNFLoc = copy.deepcopy(VNFLoc_best)\n",
    "                vnf_relocat = copy.deepcopy(vnf_relocat_best)\n",
    "            else:\n",
    "                # Pending to implement reassign procedure(): No required for the moment\n",
    "                print('error mapping-------------------')\n",
    "                flag_mapping_error = True\n",
    "                print('unfeasible_candidates', row['SessionId'], unfeasible_candidates)\n",
    "                print('feasible_cadidates', row['SessionId'], feasible_cadidates)\n",
    "                print('REASSIGN PROCEDURE: vnf_type needs to be defined')\n",
    "                raise\n",
    "#                 flag_resources_released, solution_copy = reassign_procedure(source_vnf_f, Lprop_vnf_f, vnf_type, \n",
    "#                                                                             flag_look_ahead, solution_copy, row,\n",
    "#                                                                             AVAILABLE_NC,)\n",
    "                break\n",
    "                        \n",
    "    return flag_mapping_error, solution_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DPC_UPCR(MappedSessionInfo_h, UnmapSessionInfo_h, Sort_criteria_list, Sort_order_list, solution_, \n",
    "                available_nc):\n",
    "\n",
    "    #Initial variables\n",
    "    SFCUnmapped = []\n",
    "    Count_reassig = 0\n",
    "    AVAILABLE_NC = list(capacity_nc.keys())\n",
    "\n",
    "    # updating available candidates for each user upon their new BS and determing criticism\n",
    "    MappedSessionInfo_h = critic_classifier(MappedSessionInfo_h, available_nc)\n",
    "    UnmapSessionInfo_h = critic_classifier(UnmapSessionInfo_h, available_nc)  \n",
    "    \n",
    "    #Sorting SFCR\n",
    "    if len(Sort_criteria_list) != 0:\n",
    "        UnmapSessionInfo_h = UnmapSessionInfo_h.sort_values(by=Sort_criteria_list, ascending=Sort_order_list)\n",
    "    \n",
    "    while len(UnmapSessionInfo_h) != 0:\n",
    "        solution_copy = copy.deepcopy(solution_)\n",
    "        row = UnmapSessionInfo_h.iloc[0]           # selecting the first SFCR in the sorted  set\n",
    "\n",
    "        # Procedure: mapping\n",
    "        flag_mapping_error, solution_copy = mapping_procedure(solution_copy, row, available_nc, AVAILABLE_NC)\n",
    "        # Procedure: reassign\n",
    "        if flag_mapping_error:\n",
    "            print('ERROR: reassign due to unfeasible placement: not implemented yet')\n",
    "            raise\n",
    "            flag_reasing = False\n",
    "            Count_reassig += 1\n",
    "\n",
    "        # updating the set of SFCRs\n",
    "        UnmapSessionInfo_h = UnmapSessionInfo_h.drop(UnmapSessionInfo_h.index[0]) \n",
    "        \n",
    "        # steps 40- : Update resources and (un)mapping set            \n",
    "        if not flag_mapping_error:  \n",
    "            solution_ = copy.deepcopy(solution_copy)\n",
    "            MappedSessionInfo_h = MappedSessionInfo_h.append(row)\n",
    "            #checking if we need o delete some candidate\n",
    "            flag_sort_sfcr = False\n",
    "            for c, instances in solution_['NodeVNFInstances'].items():\n",
    "                if solution_['ServersCap'][c] == 0 and c in available_nc:   # Analize available capacity of VNFs in c\n",
    "                    flag_update_c = True\n",
    "                    for typ,id_f in instances.items():\n",
    "                        for f in id_f:\n",
    "                            if solution_['VNFCapacity'][typ][f] > (1-alpha)*capacity_ct[typ]:\n",
    "                                flag_update_c = False\n",
    "                                break\n",
    "                        if not flag_update_c: break\n",
    "                    if flag_update_c:\n",
    "                        flag_sort_sfcr = True\n",
    "                        available_nc.remove(c) \n",
    "                        \n",
    "            if flag_sort_sfcr and len(Sort_criteria_list) != 0:\n",
    "                UnmapSessionInfo_h = critic_classifier(UnmapSessionInfo_h, available_nc)                \n",
    "                #Sorting SFCR \n",
    "                UnmapSessionInfo_h = UnmapSessionInfo_h.sort_values(by=Sort_criteria_list,\n",
    "                                                                    ascending=Sort_order_list)        \n",
    "        else:\n",
    "            SFCUnmapped.append(row['SessionId'])              \n",
    "            raise\n",
    "    \n",
    "    return solution_, SFCUnmapped, MappedSessionInfo_h, Count_reassig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release Assigned resources\n",
    "\n",
    "This step is executed for the first placement, only for the reconfiguration without improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_initialSolution(SessionInfo_h):\n",
    "    \"\"\" This function creates the initial solution according to the value of FLAG_ALL_SFC.\n",
    "    If True, an empty solution (all thecapacity is available) is created, otherwise, a protion of sfc are \n",
    "    selected and their assigned resources are released\"\"\"\n",
    "\n",
    "    if params.FLAG_ALL_SFC:  #if true all the sessions are analyzed during the reconfiguration. \n",
    "                             #Otherwise, the number of sessions depends of LV and ROUT_SESS\n",
    "        solution_ = {}\n",
    "        solution_['ServersCap'] = copy.deepcopy(capacity_nc)\n",
    "        solution_['LinksCap'] = copy.deepcopy(Dict_Links_Capacity)\n",
    "        solution_['OpenServers'] = []\n",
    "        solution_['VNFInstances'] = {} \n",
    "        solution_['VNFCapacity'] = {}   \n",
    "        solution_['NodeVNFInstances'] = {} \n",
    "        solution_['VNFSFCAssigned'] = {} \n",
    "        solution_['SFCMapping'] = {}\n",
    "        solution_['VNFInstances_tmp'] = {}  #this dic is used during the evauluation process to avoid \n",
    "                                            # misleading information, consider migrations\n",
    "            \n",
    "        SessionInfo_h, Lv_users_list = gathering_infoSFC(SessionInfo_h) # active if sort sessions per Lbudg\n",
    "    \n",
    "        UnmapSessionInfo_h = copy.deepcopy(SessionInfo_h)\n",
    "        MappedSessionInfo_h = pd.DataFrame(columns=list(SessionInfo_h.columns))\n",
    "\n",
    "        \n",
    "    else: \n",
    "        solution_ = generating_initialSolution()\n",
    " \n",
    "        solution_['VNFInstances_tmp'] = {}  #this dic is used during the evauluation process to avoid \n",
    "                                            # misleading information, consider migrations\n",
    "        \n",
    "        # Unmapping sessions with Latency criteria\n",
    "        SessionInfo_h, Lv_users_list = gathering_infoSFC(SessionInfo_h)       \n",
    "        SortedSessionInfo_h = SessionInfo_h.sort_values(by=['Lbudg'], ascending=[True])    #Sorting SFCR \n",
    "\n",
    "        unmap_sess_length = min(len(Lv_users_list) + int(params.LV_EXTRA_SESS*S), S)\n",
    "        UnmapSessionInfo_h = SortedSessionInfo_h[:unmap_sess_length]      # sessions to be mapped\n",
    "        MappedSessionInfo_h = SortedSessionInfo_h[unmap_sess_length:]     # sessions to keep mapped\n",
    "\n",
    "        solution_, UnmapSessionInfo_h, MappedSessionInfo_h = unmapping_sessions(solution_, \n",
    "                                                                                UnmapSessionInfo_h,\n",
    "                                                                                MappedSessionInfo_h,\n",
    "                                                                                flag_extrasfc_upf)\n",
    "\n",
    "#     if len(UnmapSessionInfo_h) + len(MappedSessionInfo_h) != S:\n",
    "#         print('ERROR: Verify mapped and unmapped sessions')\n",
    "#         raise\n",
    "\n",
    "    # Determining candidates with available capacity. This also includes the ones with available capacity\n",
    "    # in the VNFS    \n",
    "    available_nc = [ x for x in capacity_nc.keys() if x not in solution_['OpenServers']]\n",
    "\n",
    "    for c, v in solution_['NodeVNFInstances'].items():\n",
    "        for t, v1 in v.items():\n",
    "            for i in v1:\n",
    "                if solution_['VNFCapacity'][t][i] > (1-alpha)*capacity_ct[t] and c not in available_nc:\n",
    "                    available_nc.append(c)\n",
    "                    break\n",
    "\n",
    "#     print('no.unmapped sfc', len(UnmapSessionInfo_h))\n",
    "    \n",
    "    return  solution_, UnmapSessionInfo_h, MappedSessionInfo_h, available_nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session 4\n",
      "VNFLoc_aux {1: (1, [67.5])}\n",
      "VNFLoc_aux {1: (7, [11.119999999999997])}\n",
      "VNFLoc_aux {1: (2, [47.19])}\n",
      "VNFLoc_aux {1: (5, [46.05])}\n",
      "VNFLoc_aux {1: (6, [30.4])}\n",
      "VNFLoc_aux {1: (3, [29.689999999999998])}\n",
      "VNFLoc_aux {1: (10, [27.180000000000007])}\n",
      "VNFLoc_aux {1: (4, [26.009999999999998])}\n",
      "VNFLoc_aux {1: (13, [9.680000000000007])}\n",
      "VNFLoc_aux {1: (9, [6.290000000000006])}\n",
      "VNFLoc_aux {1: (11, [6.0])}\n",
      "session 25\n",
      "VNFLoc_aux {1: (1, [26.009999999999998])}\n",
      "session 5\n",
      "VNFLoc_aux {1: (1, [31.0])}\n",
      "session 19\n",
      "VNFLoc_aux {1: (1, [10.079999999999998])}\n",
      "VNFLoc_aux {1: (7, [66.46000000000001])}\n",
      "session 21\n",
      "VNFLoc_aux {1: (7, [47.73])}\n",
      "VNFLoc_aux {1: (1, [6.320000000000007])}\n",
      "session 12\n",
      "VNFLoc_aux {1: (7, [31.599999999999994])}\n",
      "session 24\n",
      "VNFLoc_aux {1: (7, [30.39])}\n",
      "session 18\n",
      "VNFLoc_aux {1: (7, [31.43])}\n",
      "session 22\n",
      "VNFLoc_aux {1: (7, [31.43])}\n",
      "session 2\n",
      "VNFLoc_aux {1: (7, [27.11])}\n",
      "session 14\n",
      "session 17\n",
      "VNFLoc_aux {1: (7, [30.840000000000003])}\n",
      "session 16\n",
      "VNFLoc_aux {1: (7, [59.3])}\n",
      "session 7\n",
      "VNFLoc_aux {1: (7, [73.3])}\n",
      "session 11\n",
      "VNFLoc_aux {1: (7, [36.21000000000001])}\n",
      "session 23\n",
      "VNFLoc_aux {1: (7, [54.870000000000005])}\n",
      "session 3\n",
      "VNFLoc_aux {1: (7, [35.08])}\n",
      "session 20\n",
      "VNFLoc_aux {1: (7, [53.93])}\n",
      "session 10\n",
      "VNFLoc_aux {1: (7, [73.25])}\n",
      "session 1\n",
      "VNFLoc_aux {1: (7, [51.81])}\n",
      "session 15\n",
      "VNFLoc_aux {1: (7, [50.65])}\n",
      "session 6\n",
      "session 8\n",
      "session 9\n",
      "session 13\n"
     ]
    }
   ],
   "source": [
    "#Sorting SFCR\n",
    "sort_criterion = params.SORT_CRITERION  # Latency\n",
    "\n",
    "#Approach folder:latency/test4\n",
    "Sort_criteria_list = ['Critic', sort_criterion,  'NumVNFs', 'SourceBS', 'NumCand',]\n",
    "Sort_order_list = [False, True,  False, True, True]\n",
    "\n",
    "#folder:latency/test2\n",
    "#     Sort_criteria_list = ['Critic', sort_criterion,  'NumVNFs', 'BS_pop', 'NumCand',]\n",
    "#     Sort_order_list = [False, True,  False, False, True] \n",
    "\n",
    "start_time = time.process_time()\n",
    "\n",
    "solution_, UnmapSessionInfo_h, MappedSessionInfo_h, available_nc = preparing_initialSolution(SessionInfo_h)\n",
    "\n",
    "best_solution_, SFCUnmapped, MappedSessionInfo_h, Count_reassig = DPC_UPCR(MappedSessionInfo_h, UnmapSessionInfo_h,\n",
    "                                                                           Sort_criteria_list, Sort_order_list, \n",
    "                                                                           solution_, available_nc)\n",
    "T_exec = time.process_time() - start_time\n",
    "\n",
    "# Checking solution\n",
    "if len(MappedSessionInfo_h) + len(SFCUnmapped) != S:\n",
    "    print('ERROR: some sessions are missing')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_solution(solution_, flag_print):\n",
    "    \n",
    "    ## Determining migrations or new deployments for the temporal VNF IDs\n",
    "    unused_vnf_is = {}      # dict with the ids of unused vnfs ids per type (key) from previous placement\n",
    "    for t,v in initial_instances_id.items():\n",
    "        for i in v:\n",
    "            if i not in solution_['VNFInstances'].get(t,[]):\n",
    "                unused_vnf_is.setdefault(t, []).append(i)\n",
    "\n",
    "    update_tmp = {}\n",
    "    Num_newdeploy = 0\n",
    "    Num_mig = 0\n",
    "    # print('PDT to define a formula to determine the relantion between both elements')\n",
    "    for t, IDs in solution_['VNFInstances_tmp'].items():\n",
    "        for id_tmp in IDs: \n",
    "            if len(unused_vnf_is.get(t, [])) != 0:\n",
    "                i = unused_vnf_is[t].pop(0)  # getting the first available id\n",
    "                Num_mig += 1\n",
    "#                 solution_['VNFInstances'][t] = [x for x in solution_['VNFInstances'][t] if x !=id_tmp]\n",
    "#                 solution_['VNFInstances'][t].append(i)\n",
    "            else:\n",
    "                for i in range(1, M_t[t]+1):\n",
    "                    if i not in solution_['VNFInstances'][t]:\n",
    "                        Num_newdeploy += 1\n",
    "#                         solution_['VNFInstances'][t] = [x for x in solution_['VNFInstances'][t] if x !=id_tmp]\n",
    "#                         solution_['VNFInstances'][t].append(i)\n",
    "                        break\n",
    "\n",
    "            update_tmp.setdefault(t, []).append((id_tmp, i))\n",
    "#     print('update_tmp, migrations, new_deploy', update_tmp, Num_mig, Num_newdeploy)\n",
    "\n",
    "    ## Processing the  solution\n",
    "    Num_upf_type = {}\n",
    "    for k,v in solution_['VNFInstances'].items():\n",
    "        Num_upf_type[k] = len(v)\n",
    "\n",
    "    Total_upf = sum([len(v) for v in solution_['VNFInstances'].values()])    \n",
    "\n",
    "    # Number of open servers\n",
    "    Num_open_c = len(solution_['OpenServers'])\n",
    "    Open_servers_list = solution_['OpenServers']\n",
    "\n",
    "    #Number of Unassigned sessions \n",
    "    Unassigned= len(SFCUnmapped)\n",
    "    Unassigned_s_list = SFCUnmapped \n",
    "\n",
    "    sfc_reloc = []\n",
    "    for (s,f,c) in Zsfc_h:\n",
    "        if solution_['SFCMapping'][s]['VNFs'][f][2] != c and s not in sfc_reloc:\n",
    "            sfc_reloc.append(s)\n",
    "    Num_reloc = len(sfc_reloc)\n",
    "\n",
    "    latency_prop = 0\n",
    "    for k,v in solution_['SFCMapping'].items():\n",
    "        for branch in SessionInfo_h[SessionInfo_h['SessionId']==k]['Presence'].values[0]:\n",
    "            latency_branch = sum([Paths[a]*b for a,b in zip(v['Paths'],branch)])  # one way and linearizando\n",
    "            latency_prop += latency_branch\n",
    "\n",
    "    variable_values = [Num_open_c, Total_upf, Num_newdeploy, Num_mig, latency_prop, \n",
    "                       Num_reloc]\n",
    "\n",
    "    cost = sum([a*b/c for a,b,c in zip(WeightFactors, variable_values, NormalizationValues)])\n",
    "                    \n",
    "    if flag_print:\n",
    "        print('   SFCs', S)\n",
    "        print('   Execution time', T_exec)\n",
    "        print('   Placement Cost', cost)\n",
    "        print('   Number of UPF installed: ', Total_upf )\n",
    "        print('   Number of new deployments', Num_newdeploy )\n",
    "        print('   Number of UPFs per type', Num_upf_type )\n",
    "        print('   Number of UPFs migrations', Num_mig )\n",
    "        print('   Open servers list', Open_servers_list )\n",
    "        print('   Number of Open Servers', Num_open_c )\n",
    "        print('   Num_unassigned sessions', Unassigned)\n",
    "        print('   Number of Relocations', Num_reloc )\n",
    "\n",
    "    return (cost, Total_upf, Num_newdeploy, Num_upf_type, Num_mig, Open_servers_list, Num_open_c,\n",
    "            sfc_reloc, Unassigned, Num_reloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SFCs 75\n",
      "   Execution time 1.671875\n",
      "   Placement Cost 0.24517332964812966\n",
      "   Number of UPF installed:  9\n",
      "   Number of new deployments 0\n",
      "   Number of UPFs per type {3: 3, 1: 3, 2: 3}\n",
      "   Number of UPFs migrations 0\n",
      "   Open servers list [5, 9, 7]\n",
      "   Number of Open Servers 3\n",
      "   Num_unassigned sessions 0\n",
      "   Number of Relocations 5\n"
     ]
    }
   ],
   "source": [
    "# the initial solution is also the best, at least at the begining\n",
    "(best_cost, Total_upf, Num_newdeploy, Num_upf_type, Num_mig, Open_servers_list, Num_open_c, \n",
    " sfc_reloc, Unassigned, Num_reloc) = processing_solution(best_solution_, flag_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_t, i 2 1\n",
      "I_t_, i_ 2 1\n",
      "2 l\n",
      "cost 0.23560854378954377\n",
      "I_t, i 1 2\n",
      "I_t_, i_ 1 2\n",
      "2 l\n",
      "cost 0.24637942863802864\n",
      "I_t, i 1 1\n",
      "I_t_, i_ 1 1\n",
      "1 lat0\n",
      "cost 0.23782187712287714\n",
      "I_t, i 2 1\n",
      "I_t_, i_ 2 1\n",
      "1 lat0\n",
      "cost 0.23560854378954377\n",
      "I_t, i 1 1\n",
      "I_t_, i_ 1 1\n",
      "0 lat4\n",
      "cost 0.23782187712287714\n",
      "I_t, i 1 2\n",
      "I_t_, i_ 1 2\n",
      "0 lat4\n",
      "cost 0.23560854378954382\n",
      "I_t, i 1 1\n",
      "I_t_, i_ 1 1\n",
      "2 l\n",
      "cost 0.24679392560772562\n",
      "I_t, i 1 3\n",
      "I_t_, i_ 1 3\n",
      "2 l\n",
      "cost 0.23527386096126096\n",
      "--> this solution is better 0.23527386096126096 0.2356085437895438\n",
      "I_t, i 1 1\n",
      "I_t_, i_ 1 1\n",
      "1 lat0\n",
      "cost 0.2425805437895438\n",
      "I_t, i 1 3\n",
      "I_t_, i_ 1 3\n",
      "0 lat4\n",
      "cost 0.23527386096126096\n",
      "   SFCs 75\n",
      "   Execution time 15.953125\n",
      "   Placement Cost 0.23527386096126096\n",
      "   Number of UPF installed:  9\n",
      "   Number of new deployments 0\n",
      "   Number of UPFs per type {1: 3, 2: 3, 3: 3}\n",
      "   Number of UPFs migrations 0\n",
      "   Open servers list [5, 9, 7]\n",
      "   Number of Open Servers 3\n",
      "   Num_unassigned sessions 0\n",
      "   Number of Relocations 1\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "if params.FLAG_HDSFC_IMPROVE:\n",
    "    SORTING_CRITERIA = [\n",
    "                        ['Critic', sort_criterion,  'NumVNFs', 'SourceBS', 'NumCand',],\n",
    "                        ['Critic', sort_criterion,  'NumVNFs', 'NumCand','SourceBS', ],\n",
    "#                         ['Critic', sort_criterion,  'NumVNFs', ],\n",
    "                        [sort_criterion],\n",
    "#                         [], \n",
    "                       ]\n",
    "    SORTING_ORDER = [\n",
    "                     [False, True,  False, True, True],\n",
    "                     [False, True,  False, True, True],\n",
    "#                      [False, True,  False],\n",
    "                     [True,],\n",
    "#                      [], \n",
    "                    ]\n",
    "    SORTING_OPTIONS = ['lat4',\n",
    "                       'lat0', \n",
    "#                        'clf', \n",
    "                       'l',\n",
    "#                        'unsorted'\n",
    "                      ]\n",
    "\n",
    "    flag_extrasfc_upf = params.FLAG_EXTRASFC_UPF_IH  # to avoid to empty another UPFs and get same result that H\n",
    "    max_try = params.MAX_HDSFC_IMPROVE   # Max. total number of instances to check in the improvement phase  \n",
    "\n",
    "    I_t, i, I_t_, i_ = 0,0,0,0\n",
    "    \n",
    "    while max_try != 0:\n",
    "        max_try -= 1\n",
    "        solution__ = copy.deepcopy(best_solution_)\n",
    "        # option_1:\n",
    "        while I_t_== I_t  and i_ == i:\n",
    "            I_t = random.choice(list(solution__['VNFInstances'].keys()))\n",
    "            i = random.choice(list(solution__['VNFInstances'][I_t]))        \n",
    "        I_t_, i_ = I_t, i\n",
    "        \n",
    "        sessions_to_unmap = solution__['VNFSFCAssigned'][I_t][i]\n",
    "        UnmapSessionInfo_h = pd.DataFrame()\n",
    "        MappedSessionInfo_h = pd.DataFrame()\n",
    "        for index, row in SessionInfo_h.iterrows():\n",
    "            if row['SessionId'] in sessions_to_unmap:\n",
    "                UnmapSessionInfo_h = UnmapSessionInfo_h.append(row)\n",
    "            else:\n",
    "                MappedSessionInfo_h = MappedSessionInfo_h.append(row)\n",
    "\n",
    "#             if len(UnmapSessionInfo_h) != len(sessions_to_unmap):\n",
    "#                 print('error')\n",
    "#                 raise\n",
    "#         print(len(UnmapSessionInfo_h))\n",
    "\n",
    "        start_time = time.process_time()\n",
    "# \n",
    "        tmp_solution_,UnmapSessionInfo_h,MappedSessionInfo_h = unmapping_sessions(solution__, \n",
    "                                                                                UnmapSessionInfo_h,\n",
    "                                                                                MappedSessionInfo_h, \n",
    "                                                                                   flag_extrasfc_upf) \n",
    "#             if len(MappedSessionInfo_h)+len(UnmapSessionInfo_h) != S:\n",
    "#                 raise\n",
    "\n",
    "        # Update available candidates\n",
    "        available_nc = [ x for x in capacity_nc.keys() if x not in tmp_solution_['OpenServers']]\n",
    "        for c, v in tmp_solution_['NodeVNFInstances'].items():\n",
    "            for t, v1 in v.items():\n",
    "                for ix in v1:\n",
    "                    if tmp_solution_['VNFCapacity'][t][ix] > (1-alpha)*capacity_ct[t] and c not in available_nc:\n",
    "                        available_nc.append(c)\n",
    "                        break\n",
    "        # DEFINING THE SORTING CRITERIA (RANDOMLY)\n",
    "        option = random.choice(range(len(SORTING_OPTIONS)))\n",
    "        Sort_criteria_list = SORTING_CRITERIA[option]\n",
    "        Sort_order_list = SORTING_ORDER[option]\n",
    "#         print(option, SORTING_OPTIONS[option])\n",
    "#         print(len(UnmapSessionInfo_h))\n",
    "\n",
    "        tmp_solution_, SFCUnmapped, MappedSessionInfo_h, Count_reassig = DPC_UPCR(MappedSessionInfo_h, \n",
    "                                                                                  UnmapSessionInfo_h, \n",
    "                                                                                  Sort_criteria_list, \n",
    "                                                                                  Sort_order_list,\n",
    "                                                                               tmp_solution_, available_nc)\n",
    "#             if len(MappedSessionInfo_h)+len(SFCUnmapped) != S:\n",
    "#                 raise\n",
    "        if len(tmp_solution_['SFCMapping']) == S:\n",
    "            (cost, Total_upf, Num_newdeploy, Num_upf_type, \n",
    "             Num_mig, Open_servers_list, Num_open_c,\n",
    "             sfc_reloc, Unassigned, Num_reloc) = processing_solution(tmp_solution_, flag_print=False)\n",
    "#             print('cost', cost)\n",
    "            if round(cost,4) < round(best_cost,4):\n",
    "#                 print('--> this solution is better', cost, best_cost)\n",
    "                best_cost = cost\n",
    "                best_solution_ = copy.deepcopy(tmp_solution_)\n",
    "        else:\n",
    "            print('unfeasible or error ', SFCUnmapped)\n",
    "            raise\n",
    "\n",
    "        T_exec += (time.process_time() - start_time)\n",
    "    \n",
    "    (best_cost ,Total_upf, Num_newdeploy, Num_upf_type, Num_mig, Open_servers_list, Num_open_c,\n",
    "            sfc_reloc, Unassigned, Num_reloc) = processing_solution(best_solution_, flag_print=True)\n",
    "    print('--------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining migrations or new deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determining migrations or new deployments\n",
    "unused_vnf_is = {}      # dict with the ids of unused vnfs ids per type (key) from previous placement\n",
    "for t,v in initial_instances_id.items():\n",
    "    for i in v:\n",
    "        if i not in best_solution_['VNFInstances'].get(t,[]):\n",
    "            unused_vnf_is.setdefault(t, []).append(i)\n",
    "print('unused_vnf_is', unused_vnf_is)\n",
    "\n",
    "update_tmp = {}\n",
    "Num_newdeploy = 0\n",
    "Num_mig = 0\n",
    "# print('PDT to define a formula to determine the relantion between both elements')\n",
    "for t, IDs in best_solution_['VNFInstances_tmp'].items():\n",
    "    for id_tmp in IDs: \n",
    "        if len(unused_vnf_is.get(t, [])) != 0:\n",
    "            i = unused_vnf_is[t].pop(0)  # getting the first available id\n",
    "            Num_mig += 1\n",
    "            best_solution_['VNFInstances'][t] = [x for x in best_solution_['VNFInstances'][t] if x !=id_tmp]\n",
    "            best_solution_['VNFInstances'][t].append(i)\n",
    "        else:\n",
    "            for i in range(1, M_t[t]+1):\n",
    "                if i not in best_solution_['VNFInstances'][t]:\n",
    "                    Num_newdeploy += 1\n",
    "                    best_solution_['VNFInstances'][t] = [x for x in best_solution_['VNFInstances'][t] if x !=id_tmp]\n",
    "                    best_solution_['VNFInstances'][t].append(i)\n",
    "                    break\n",
    "\n",
    "        update_tmp.setdefault(t, []).append((id_tmp, i))\n",
    "print('update_tmp, migrations, new_deploy', update_tmp, Num_mig, Num_newdeploy)\n",
    "\n",
    "# Updating temporary Ids due to migrations\n",
    "for t, Ids_pairs in update_tmp.items():\n",
    "    for id_pair in Ids_pairs:\n",
    "        best_solution_['VNFCapacity'][t][id_pair[1]] = best_solution_['VNFCapacity'][t][id_pair[0]]\n",
    "        del best_solution_['VNFCapacity'][t][id_pair[0]]\n",
    "        best_solution_['VNFSFCAssigned'][t][id_pair[1]] = best_solution_['VNFSFCAssigned'][t][id_pair[0]]\n",
    "        del best_solution_['VNFSFCAssigned'][t][id_pair[0]]\n",
    "        for c, v in best_solution_['NodeVNFInstances'].items():\n",
    "            if id_pair[0] in best_solution_['NodeVNFInstances'][c].get(t, []):\n",
    "                best_solution_['NodeVNFInstances'][c][t] = [i for i in best_solution_['NodeVNFInstances'][c][t]\n",
    "                                                       if i !=id_pair[0]]\n",
    "                best_solution_['NodeVNFInstances'][c][t].append(id_pair[1])\n",
    "        for s, v  in best_solution_['SFCMapping'].items():\n",
    "            for f, tic in v['VNFs'].items():\n",
    "                if tic[0]==t and tic[1]==id_pair[0]:\n",
    "                    best_solution_['SFCMapping'][s]['VNFs'][f] = (t, id_pair[1], tic[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
